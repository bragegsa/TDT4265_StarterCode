{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# url = \"https://drive.google.com/uc?id=1gtP1McQNNnNkQl9d4cz8aiUsnCkXWOI3&export=download\"\n",
    "# r = requests.get(url)\n",
    "# with open('input.zip', 'wb') as f:\n",
    "#    f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -xf input.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# url = \"https://drive.google.com/uc?id=1GxuLED7FGsfa5VtI_DCWnwyP0TDrTwFe&export=download\"\n",
    "# r = requests.get(url)\n",
    "# with open('LOC_synset_mapping.txt', 'wb') as f:\n",
    "#    f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cam.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cam.py\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "from ..configs.exploration_knowledge_config_2 import (model, gpu_transform)\n",
    "\n",
    "from configs.exploration_knowledge_config_2 import model, gpu_transform\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torch import topk\n",
    "\n",
    "# construct the argument parser\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-i', '--input', help='path to input image', \n",
    "                    default='../data/tdt4265_2022_updated/images/val/trip007_glos_Video00003_0.png')\n",
    "args = vars(parser.parse_args())\n",
    "\n",
    "# https://github.com/zhoubolei/CAM/blob/master/pytorch_CAM.py\n",
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        cam = weight_softmax[idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam\n",
    "\n",
    "def show_cam(CAMs, width, height, orig_image, class_idx, all_classes, save_name):\n",
    "    for i, cam in enumerate(CAMs):\n",
    "        heatmap = cv2.applyColorMap(cv2.resize(cam,(width, height)), cv2.COLORMAP_JET)\n",
    "        result = heatmap * 0.3 + orig_image * 0.5\n",
    "        # put class label text on the result\n",
    "        cv2.putText(result, all_classes[class_idx[i]], (20, 40), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 2)\n",
    "        # cv2.imshow('CAM', result/255.)\n",
    "        # cv2.waitKey(0)\n",
    "        cv2.imwrite(f\"outputs/CAM_{save_name}.jpg\", result)\n",
    "\n",
    "def load_synset_classes(file_path):\n",
    "    # load the synset text file for labels\n",
    "    all_classes = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        all_lines = f.readlines()\n",
    "        labels = [line.split('\\n') for line in all_lines]\n",
    "        for label_list in labels:\n",
    "            current_class = [name.split(',') for name in label_list][0][0][10:]\n",
    "            all_classes.append(current_class)\n",
    "    return all_classes\n",
    "\n",
    "# get all the classes in a list\n",
    "all_classes = load_synset_classes('LOC_synset_mapping.txt')\n",
    "\n",
    "# read and visualize the image\n",
    "image = cv2.imread(args['input'])\n",
    "orig_image = image.copy()\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "height, width, _ = image.shape\n",
    "\n",
    "# load the model\n",
    "model = model\n",
    "# hook the feature extractor\n",
    "# https://github.com/zhoubolei/CAM/blob/master/pytorch_CAM.py\n",
    "features_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())\n",
    "model._modules.get('layer4').register_forward_hook(hook_feature)\n",
    "# get the softmax weight\n",
    "params = list(model.parameters())\n",
    "weight_softmax = np.squeeze(params[-2].data.numpy())\n",
    "\n",
    "# define the transforms, resize => tensor => normalize\n",
    "# transforms = transforms.Compose(\n",
    "#     [transforms.ToPILImage(),\n",
    "#      transforms.Resize((224, 224)),\n",
    "#      transforms.ToTensor(),\n",
    "#      transforms.Normalize(\n",
    "#         mean=[0.485, 0.456, 0.406],\n",
    "#         std=[0.229, 0.224, 0.225]\n",
    "#     )\n",
    "#     ])\n",
    "\n",
    "transforms = gpu_transform\n",
    "\n",
    "# apply the image transforms\n",
    "image_tensor = transforms(image)\n",
    "# add batch dimension\n",
    "image_tensor = image_tensor.unsqueeze(0)\n",
    "# forward pass through model\n",
    "outputs = model(image_tensor)\n",
    "# get the softmax probabilities\n",
    "probs = F.softmax(outputs).data.squeeze()\n",
    "# get the class indices of top k probabilities\n",
    "class_idx = topk(probs, 1)[1].int()\n",
    "\n",
    "# generate class activation mapping for the top1 prediction\n",
    "CAMs = returnCAM(features_blobs[0], weight_softmax, class_idx)\n",
    "# file name to save the resulting CAM image with\n",
    "save_name = f\"{args['input'].split('/')[-1].split('.')[0]}\"\n",
    "# show and save the results\n",
    "show_cam(CAMs, width, height, orig_image, class_idx, all_classes, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nikla\\Documents\\GitHub\\TDT4265_Project\\TDT4265_StarterCode\\assignment4\\SSD\\dataset_exploration\\cam.py\", line 5, in <module>\n",
      "    from ..configs.exploration_knowledge_config_2 import (model, gpu_transform)\n",
      "ImportError: attempted relative import with no known parent package\n"
     ]
    }
   ],
   "source": [
    "!python cam.py --input ../data/tdt4265_2022_updated/images/val/trip007_glos_Video00003_0.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nikla\\Documents\\GitHub\\TDT4265_Project\\TDT4265_StarterCode\\assignment4\\SSD\\dataset_exploration\\cam.py\", line 5, in <module>\n",
      "    from ..configs.exploration_knowledge_config_2 import (model, gpu_transform)\n",
      "ImportError: attempted relative import with no known parent package\n"
     ]
    }
   ],
   "source": [
    "!python cam.py --input ../data/tdt4265_2022_updated/images/val/trip007_glos_Video00003_77.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = 15, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_1 = plt.imread('\\outputs\\CAM_image_1.jpg')\n",
    "# plt.imshow(image_1)\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# image_2 = plt.imread('\\outputs\\CAM_image_2.jpg')\n",
    "# plt.imshow(image_2)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
